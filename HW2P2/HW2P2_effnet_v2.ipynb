{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBITN0M_LKds"
   },
   "source": [
    "# HW2P2: Face Classification and Verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NH4P-HzLRQs"
   },
   "source": [
    "Congrats on coming to the second homework in 11785: Introduction to Deep Learning. This homework significantly longer and tougher than the previous homework. You have 2 sub-parts as outlined below. Please start early! \n",
    "\n",
    "\n",
    "*   Face Recognition: You will be writing your own CNN model to tackle the problem of classification, consisting of 7000 identities\n",
    "*   Face Verification: You use the model trained for classification to evaluate the quality of its feature embeddings, by comparing the similarity of known and unknown identities\n",
    "\n",
    "For this HW, you only have to write code to implement your model architecture. Everything else has been provided for you, on the pretext that most of your time will be used up in developing the suitable model architecture for achieving satisfactory performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1B_m84_cU6c"
   },
   "source": [
    "Common errors which you may face in this homeworks (because of the size of the model)\n",
    "\n",
    "\n",
    "*   CUDA Out of Memory (OOM): You can tackle this problem by (1) Reducing the batch size (2) Calling `torch.cuda.empty_cache()` and `gc.collect()` (3) Finally restarting the runtime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdoDIKWOMF59"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jza7lwiScUhb"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi # to see what GPU you have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bTxfd_nqFnL9"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwLEd0gdPbSc",
    "outputId": "b8988980-9fbe-4dd5-ed05-2f685d7fb1b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "import torchvision #This library is used for image-based operations (Augmentations)\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "import wandb\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRz9et3SZnbO",
    "outputId": "33ef3f5c-c01a-4775-de49-fde8184eb18e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive # Link your drive if you are a colab user\n",
    "# drive.mount('/content/drive') # Models in this HW take a long time to get trained and make sure to save it her"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oxQNl-YVWHc"
   },
   "source": [
    "# TODOs\n",
    "As you go, please read the code and keep an eye out for TODOs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scOnMklwWBY6"
   },
   "source": [
    "# Download Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6BksgPdkQwwb"
   },
   "outputs": [],
   "source": [
    "# TODO: Use the same Kaggle code from HW1P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3oFjaJTaRjT7"
   },
   "outputs": [],
   "source": [
    "# !mkdir 'data'\n",
    "\n",
    "# !kaggle competitions download -c 11-785-f22-hw2p2-classification\n",
    "# !unzip -qo '11-785-f22-hw2p2-classification.zip' -d 'data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c 11-785-f22-hw2p2-verification\n",
    "# !unzip -qo '11-785-f22-hw2p2-verification.zip' -d 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O68hT27SXClj"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "S7qpMxG0XCJz"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 64, # Increase this if your GPU can handle it\n",
    "    'lr': 0.2,\n",
    "    'epochs': 100, # 10 epochs is recommended ONLY for the early submission - you will have to train for much longer typically.\n",
    "    'optimizer':'SGD',\n",
    "    'weight_decay': 1e-5,\n",
    "    'scheduler':'CosineLR',\n",
    "    'LR_stepsize': 'batch*epochs',\n",
    "    'smoothing': 0.1,\n",
    "    'dropout': 0.15\n",
    "    # Include other parameters as needed.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSeiKHYrM-6b"
   },
   "source": [
    "# Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.51302713, 0.4033568, 0.35215932), (0.3069095, 0.26970628, 0.25837687))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('normalization_parameters.pkl', 'rb') as f:\n",
    "    [mean, std] = pickle.load(f)\n",
    "tuple(mean), tuple(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tmRX5omaNDEZ"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/11-785-f22-hw2p2-classification/'# TODO: Path where you have downloaded the data\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"classification/train\") \n",
    "VAL_DIR = os.path.join(DATA_DIR, \"classification/dev\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"classification/test\")\n",
    "\n",
    "# Transforms using torchvision - Refer https://pytorch.org/vision/stable/transforms.html\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose([ \n",
    "    # Implementing the right transforms/augmentation methods is key to improving performance.\n",
    "                    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "                    torchvision.transforms.RandomAdjustSharpness(0.2),\n",
    "#                     torchvision.transforms.RandomResizedCrop(224),\n",
    "                    torchvision.transforms.GaussianBlur(kernel_size=7),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(tuple(mean), tuple(std))\n",
    "                    ])\n",
    "# Most torchvision transforms are done on PIL images. So you convert it into a tensor at the end with ToTensor()\n",
    "# But there are some transforms which are performed after ToTensor() : e.g - Normalization\n",
    "# Normalization Tip - Do not blindly use normalization that is not suitable for this dataset\n",
    "\n",
    "val_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Normalize(mean, std)\n",
    "                                                ])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR, transform = train_transforms)\n",
    "val_dataset = torchvision.datasets.ImageFolder(VAL_DIR, transform = val_transforms)\n",
    "# You should NOT have data augmentation on the validation set. Why?\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = config['batch_size'], \n",
    "                                           shuffle = True,num_workers = 4, pin_memory = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = config['batch_size'], \n",
    "                                         shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SqSR063BGE2e"
   },
   "outputs": [],
   "source": [
    "# You can do this with ImageFolder as well, but it requires some tweaking\n",
    "class ClassificationTestDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, transforms):\n",
    "        self.data_dir   = data_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # This one-liner basically generates a sorted list of full paths to each image in the test directory\n",
    "        self.img_paths  = list(map(lambda fname: os.path.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transforms(Image.open(self.img_paths[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fVLB41KtGC2o"
   },
   "outputs": [],
   "source": [
    "test_dataset = ClassificationTestDataset(TEST_DIR, transforms = val_transforms) #Why are we using val_transforms for Test Data?\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = config['batch_size'], shuffle = False,\n",
    "                         drop_last = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4t8eU9gY0Jy",
    "outputId": "6c93757b-7b48-4f1d-cc6c-524bd866c004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  7000\n",
      "No. of train images:  140000\n",
      "Shape of image:  torch.Size([3, 224, 224])\n",
      "Batch size:  64\n",
      "Train batches:  2188\n",
      "Val batches:  547\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of classes: \", len(train_dataset.classes))\n",
    "print(\"No. of train images: \", train_dataset.__len__())\n",
    "print(\"Shape of image: \", train_dataset[0][0].shape)\n",
    "print(\"Batch size: \", config['batch_size'])\n",
    "print(\"Train batches: \", train_loader.__len__())\n",
    "print(\"Val batches: \", val_loader.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIqmojPaWD0H"
   },
   "source": [
    "# Efficient Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_efficientnet_v2_hyperparam(model_name):\n",
    "    from box import Box\n",
    "    # train_size, eval_size, dropout, randaug, mixup\n",
    "    if 'efficientnet_v2_s' in model_name:\n",
    "        end = 300, 384, 0.2, 10, 0\n",
    "    elif 'efficientnet_v2_m' in model_name:\n",
    "        end = 384, 480, 0.3, 15, 0.2\n",
    "    elif 'efficientnet_v2_l' in model_name:\n",
    "        end = 384, 480, 0.4, 20, 0.5\n",
    "    elif 'efficientnet_v2_xl' in model_name:\n",
    "        end = 384, 512, 0.4, 20, 0.5\n",
    "    return Box({\"init_train_size\": 128, \"init_dropout\": 0.1, \"init_randaug\": 5, \"init_mixup\": 0,\n",
    "             \"end_train_size\": end[0], \"end_dropout\": end[2], \"end_randaug\": end[3], \"end_mixup\": end[4], \"eval_size\": end[1]})\n",
    "\n",
    "\n",
    "def get_efficientnet_v2_structure(model_name):\n",
    "    if 'efficientnet_v2_s' in model_name:\n",
    "        return [\n",
    "            # e k  s  in  out xN  se   fused\n",
    "            (1, 3, 1, 24, 24, 2, False, True),\n",
    "            (4, 3, 2, 24, 48, 4, False, True),\n",
    "            (4, 3, 2, 48, 64, 4, False, True),\n",
    "            (4, 3, 2, 64, 128, 6, True, False),\n",
    "            (6, 3, 1, 128, 160, 9, True, False),\n",
    "            (6, 3, 2, 160, 256, 15, True, False),\n",
    "        ]\n",
    "    elif 'efficientnet_v2_m' in model_name:\n",
    "        return [\n",
    "            # e k  s  in  out xN  se   fused\n",
    "            (1, 3, 1, 24, 24, 3, False, True),\n",
    "            (4, 3, 2, 24, 48, 5, False, True),\n",
    "            (4, 3, 2, 48, 80, 5, False, True),\n",
    "            (4, 3, 2, 80, 160, 7, True, False),\n",
    "            (6, 3, 1, 160, 176, 14, True, False),\n",
    "            (6, 3, 2, 176, 304, 18, True, False),\n",
    "            (6, 3, 1, 304, 512, 5, True, False),\n",
    "        ]\n",
    "    elif 'efficientnet_v2_l' in model_name:\n",
    "        return [\n",
    "            # e k  s  in  out xN  se   fused\n",
    "            (1, 3, 1, 32, 32, 4, False, True),\n",
    "            (4, 3, 2, 32, 64, 7, False, True),\n",
    "            (4, 3, 2, 64, 96, 7, False, True),\n",
    "            (4, 3, 2, 96, 192, 10, True, False),\n",
    "            (6, 3, 1, 192, 224, 19, True, False),\n",
    "            (6, 3, 2, 224, 384, 25, True, False),\n",
    "            (6, 3, 1, 384, 640, 7, True, False),\n",
    "        ]\n",
    "    elif 'efficientnet_v2_xl' in model_name:\n",
    "        return [\n",
    "            # e k  s  in  out xN  se   fused\n",
    "            (1, 3, 1, 32, 32, 4, False, True),\n",
    "            (4, 3, 2, 32, 64, 8, False, True),\n",
    "            (4, 3, 2, 64, 96, 8, False, True),\n",
    "            (4, 3, 2, 96, 192, 16, True, False),\n",
    "            (6, 3, 1, 192, 256, 24, True, False),\n",
    "            (6, 3, 2, 256, 512, 32, True, False),\n",
    "            (6, 3, 1, 512, 640, 8, True, False),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from effnet_v2 import *\n",
    "\n",
    "# model = get_efficientnet_v2(model_name, pretrained, num_classes, dropout=dropout)\n",
    "model_name = 'efficientnet_v2_m'\n",
    "nclass = 7000\n",
    "dropout = config['dropout']\n",
    "stochastic_depth = 0.2\n",
    "\n",
    "\n",
    "residual_config = [MBConvConfig(*layer_config) for layer_config in get_efficientnet_v2_structure(model_name)]\n",
    "model = EfficientNetV2(residual_config, 1280, nclass, dropout=dropout, stochastic_depth=stochastic_depth, block=MBConv, act_layer=nn.SiLU)\n",
    "efficientnet_v2_init(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 24, 112, 112]             648\n",
      "       BatchNorm2d-2         [-1, 24, 112, 112]              48\n",
      "              SiLU-3         [-1, 24, 112, 112]               0\n",
      "            Conv2d-4         [-1, 24, 112, 112]           5,184\n",
      "       BatchNorm2d-5         [-1, 24, 112, 112]              48\n",
      "              SiLU-6         [-1, 24, 112, 112]               0\n",
      "   StochasticDepth-7         [-1, 24, 112, 112]               0\n",
      "            MBConv-8         [-1, 24, 112, 112]               0\n",
      "            Conv2d-9         [-1, 24, 112, 112]           5,184\n",
      "      BatchNorm2d-10         [-1, 24, 112, 112]              48\n",
      "             SiLU-11         [-1, 24, 112, 112]               0\n",
      "  StochasticDepth-12         [-1, 24, 112, 112]               0\n",
      "           MBConv-13         [-1, 24, 112, 112]               0\n",
      "           Conv2d-14         [-1, 24, 112, 112]           5,184\n",
      "      BatchNorm2d-15         [-1, 24, 112, 112]              48\n",
      "             SiLU-16         [-1, 24, 112, 112]               0\n",
      "  StochasticDepth-17         [-1, 24, 112, 112]               0\n",
      "           MBConv-18         [-1, 24, 112, 112]               0\n",
      "           Conv2d-19           [-1, 96, 56, 56]          20,736\n",
      "      BatchNorm2d-20           [-1, 96, 56, 56]             192\n",
      "             SiLU-21           [-1, 96, 56, 56]               0\n",
      "           Conv2d-22           [-1, 48, 56, 56]           4,608\n",
      "      BatchNorm2d-23           [-1, 48, 56, 56]              96\n",
      "         Identity-24           [-1, 48, 56, 56]               0\n",
      "           MBConv-25           [-1, 48, 56, 56]               0\n",
      "           Conv2d-26          [-1, 192, 56, 56]          82,944\n",
      "      BatchNorm2d-27          [-1, 192, 56, 56]             384\n",
      "             SiLU-28          [-1, 192, 56, 56]               0\n",
      "           Conv2d-29           [-1, 48, 56, 56]           9,216\n",
      "      BatchNorm2d-30           [-1, 48, 56, 56]              96\n",
      "         Identity-31           [-1, 48, 56, 56]               0\n",
      "  StochasticDepth-32           [-1, 48, 56, 56]               0\n",
      "           MBConv-33           [-1, 48, 56, 56]               0\n",
      "           Conv2d-34          [-1, 192, 56, 56]          82,944\n",
      "      BatchNorm2d-35          [-1, 192, 56, 56]             384\n",
      "             SiLU-36          [-1, 192, 56, 56]               0\n",
      "           Conv2d-37           [-1, 48, 56, 56]           9,216\n",
      "      BatchNorm2d-38           [-1, 48, 56, 56]              96\n",
      "         Identity-39           [-1, 48, 56, 56]               0\n",
      "  StochasticDepth-40           [-1, 48, 56, 56]               0\n",
      "           MBConv-41           [-1, 48, 56, 56]               0\n",
      "           Conv2d-42          [-1, 192, 56, 56]          82,944\n",
      "      BatchNorm2d-43          [-1, 192, 56, 56]             384\n",
      "             SiLU-44          [-1, 192, 56, 56]               0\n",
      "           Conv2d-45           [-1, 48, 56, 56]           9,216\n",
      "      BatchNorm2d-46           [-1, 48, 56, 56]              96\n",
      "         Identity-47           [-1, 48, 56, 56]               0\n",
      "  StochasticDepth-48           [-1, 48, 56, 56]               0\n",
      "           MBConv-49           [-1, 48, 56, 56]               0\n",
      "           Conv2d-50          [-1, 192, 56, 56]          82,944\n",
      "      BatchNorm2d-51          [-1, 192, 56, 56]             384\n",
      "             SiLU-52          [-1, 192, 56, 56]               0\n",
      "           Conv2d-53           [-1, 48, 56, 56]           9,216\n",
      "      BatchNorm2d-54           [-1, 48, 56, 56]              96\n",
      "         Identity-55           [-1, 48, 56, 56]               0\n",
      "  StochasticDepth-56           [-1, 48, 56, 56]               0\n",
      "           MBConv-57           [-1, 48, 56, 56]               0\n",
      "           Conv2d-58          [-1, 192, 28, 28]          82,944\n",
      "      BatchNorm2d-59          [-1, 192, 28, 28]             384\n",
      "             SiLU-60          [-1, 192, 28, 28]               0\n",
      "           Conv2d-61           [-1, 80, 28, 28]          15,360\n",
      "      BatchNorm2d-62           [-1, 80, 28, 28]             160\n",
      "         Identity-63           [-1, 80, 28, 28]               0\n",
      "           MBConv-64           [-1, 80, 28, 28]               0\n",
      "           Conv2d-65          [-1, 320, 28, 28]         230,400\n",
      "      BatchNorm2d-66          [-1, 320, 28, 28]             640\n",
      "             SiLU-67          [-1, 320, 28, 28]               0\n",
      "           Conv2d-68           [-1, 80, 28, 28]          25,600\n",
      "      BatchNorm2d-69           [-1, 80, 28, 28]             160\n",
      "         Identity-70           [-1, 80, 28, 28]               0\n",
      "  StochasticDepth-71           [-1, 80, 28, 28]               0\n",
      "           MBConv-72           [-1, 80, 28, 28]               0\n",
      "           Conv2d-73          [-1, 320, 28, 28]         230,400\n",
      "      BatchNorm2d-74          [-1, 320, 28, 28]             640\n",
      "             SiLU-75          [-1, 320, 28, 28]               0\n",
      "           Conv2d-76           [-1, 80, 28, 28]          25,600\n",
      "      BatchNorm2d-77           [-1, 80, 28, 28]             160\n",
      "         Identity-78           [-1, 80, 28, 28]               0\n",
      "  StochasticDepth-79           [-1, 80, 28, 28]               0\n",
      "           MBConv-80           [-1, 80, 28, 28]               0\n",
      "           Conv2d-81          [-1, 320, 28, 28]         230,400\n",
      "      BatchNorm2d-82          [-1, 320, 28, 28]             640\n",
      "             SiLU-83          [-1, 320, 28, 28]               0\n",
      "           Conv2d-84           [-1, 80, 28, 28]          25,600\n",
      "      BatchNorm2d-85           [-1, 80, 28, 28]             160\n",
      "         Identity-86           [-1, 80, 28, 28]               0\n",
      "  StochasticDepth-87           [-1, 80, 28, 28]               0\n",
      "           MBConv-88           [-1, 80, 28, 28]               0\n",
      "           Conv2d-89          [-1, 320, 28, 28]         230,400\n",
      "      BatchNorm2d-90          [-1, 320, 28, 28]             640\n",
      "             SiLU-91          [-1, 320, 28, 28]               0\n",
      "           Conv2d-92           [-1, 80, 28, 28]          25,600\n",
      "      BatchNorm2d-93           [-1, 80, 28, 28]             160\n",
      "         Identity-94           [-1, 80, 28, 28]               0\n",
      "  StochasticDepth-95           [-1, 80, 28, 28]               0\n",
      "           MBConv-96           [-1, 80, 28, 28]               0\n",
      "           Conv2d-97          [-1, 320, 28, 28]          25,600\n",
      "      BatchNorm2d-98          [-1, 320, 28, 28]             640\n",
      "             SiLU-99          [-1, 320, 28, 28]               0\n",
      "          Conv2d-100          [-1, 320, 14, 14]           2,880\n",
      "     BatchNorm2d-101          [-1, 320, 14, 14]             640\n",
      "            SiLU-102          [-1, 320, 14, 14]               0\n",
      "AdaptiveAvgPool2d-103            [-1, 320, 1, 1]               0\n",
      "          Conv2d-104             [-1, 20, 1, 1]           6,420\n",
      "            SiLU-105             [-1, 20, 1, 1]               0\n",
      "          Conv2d-106            [-1, 320, 1, 1]           6,720\n",
      "         Sigmoid-107            [-1, 320, 1, 1]               0\n",
      "          SEUnit-108          [-1, 320, 14, 14]               0\n",
      "          Conv2d-109          [-1, 160, 14, 14]          51,200\n",
      "     BatchNorm2d-110          [-1, 160, 14, 14]             320\n",
      "        Identity-111          [-1, 160, 14, 14]               0\n",
      "          MBConv-112          [-1, 160, 14, 14]               0\n",
      "          Conv2d-113          [-1, 640, 14, 14]         102,400\n",
      "     BatchNorm2d-114          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-115          [-1, 640, 14, 14]               0\n",
      "          Conv2d-116          [-1, 640, 14, 14]           5,760\n",
      "     BatchNorm2d-117          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-118          [-1, 640, 14, 14]               0\n",
      "AdaptiveAvgPool2d-119            [-1, 640, 1, 1]               0\n",
      "          Conv2d-120             [-1, 40, 1, 1]          25,640\n",
      "            SiLU-121             [-1, 40, 1, 1]               0\n",
      "          Conv2d-122            [-1, 640, 1, 1]          26,240\n",
      "         Sigmoid-123            [-1, 640, 1, 1]               0\n",
      "          SEUnit-124          [-1, 640, 14, 14]               0\n",
      "          Conv2d-125          [-1, 160, 14, 14]         102,400\n",
      "     BatchNorm2d-126          [-1, 160, 14, 14]             320\n",
      "        Identity-127          [-1, 160, 14, 14]               0\n",
      " StochasticDepth-128          [-1, 160, 14, 14]               0\n",
      "          MBConv-129          [-1, 160, 14, 14]               0\n",
      "          Conv2d-130          [-1, 640, 14, 14]         102,400\n",
      "     BatchNorm2d-131          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-132          [-1, 640, 14, 14]               0\n",
      "          Conv2d-133          [-1, 640, 14, 14]           5,760\n",
      "     BatchNorm2d-134          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-135          [-1, 640, 14, 14]               0\n",
      "AdaptiveAvgPool2d-136            [-1, 640, 1, 1]               0\n",
      "          Conv2d-137             [-1, 40, 1, 1]          25,640\n",
      "            SiLU-138             [-1, 40, 1, 1]               0\n",
      "          Conv2d-139            [-1, 640, 1, 1]          26,240\n",
      "         Sigmoid-140            [-1, 640, 1, 1]               0\n",
      "          SEUnit-141          [-1, 640, 14, 14]               0\n",
      "          Conv2d-142          [-1, 160, 14, 14]         102,400\n",
      "     BatchNorm2d-143          [-1, 160, 14, 14]             320\n",
      "        Identity-144          [-1, 160, 14, 14]               0\n",
      " StochasticDepth-145          [-1, 160, 14, 14]               0\n",
      "          MBConv-146          [-1, 160, 14, 14]               0\n",
      "          Conv2d-147          [-1, 640, 14, 14]         102,400\n",
      "     BatchNorm2d-148          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-149          [-1, 640, 14, 14]               0\n",
      "          Conv2d-150          [-1, 640, 14, 14]           5,760\n",
      "     BatchNorm2d-151          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-152          [-1, 640, 14, 14]               0\n",
      "AdaptiveAvgPool2d-153            [-1, 640, 1, 1]               0\n",
      "          Conv2d-154             [-1, 40, 1, 1]          25,640\n",
      "            SiLU-155             [-1, 40, 1, 1]               0\n",
      "          Conv2d-156            [-1, 640, 1, 1]          26,240\n",
      "         Sigmoid-157            [-1, 640, 1, 1]               0\n",
      "          SEUnit-158          [-1, 640, 14, 14]               0\n",
      "          Conv2d-159          [-1, 160, 14, 14]         102,400\n",
      "     BatchNorm2d-160          [-1, 160, 14, 14]             320\n",
      "        Identity-161          [-1, 160, 14, 14]               0\n",
      " StochasticDepth-162          [-1, 160, 14, 14]               0\n",
      "          MBConv-163          [-1, 160, 14, 14]               0\n",
      "          Conv2d-164          [-1, 640, 14, 14]         102,400\n",
      "     BatchNorm2d-165          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-166          [-1, 640, 14, 14]               0\n",
      "          Conv2d-167          [-1, 640, 14, 14]           5,760\n",
      "     BatchNorm2d-168          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-169          [-1, 640, 14, 14]               0\n",
      "AdaptiveAvgPool2d-170            [-1, 640, 1, 1]               0\n",
      "          Conv2d-171             [-1, 40, 1, 1]          25,640\n",
      "            SiLU-172             [-1, 40, 1, 1]               0\n",
      "          Conv2d-173            [-1, 640, 1, 1]          26,240\n",
      "         Sigmoid-174            [-1, 640, 1, 1]               0\n",
      "          SEUnit-175          [-1, 640, 14, 14]               0\n",
      "          Conv2d-176          [-1, 160, 14, 14]         102,400\n",
      "     BatchNorm2d-177          [-1, 160, 14, 14]             320\n",
      "        Identity-178          [-1, 160, 14, 14]               0\n",
      " StochasticDepth-179          [-1, 160, 14, 14]               0\n",
      "          MBConv-180          [-1, 160, 14, 14]               0\n",
      "          Conv2d-181          [-1, 640, 14, 14]         102,400\n",
      "     BatchNorm2d-182          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-183          [-1, 640, 14, 14]               0\n",
      "          Conv2d-184          [-1, 640, 14, 14]           5,760\n",
      "     BatchNorm2d-185          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-186          [-1, 640, 14, 14]               0\n",
      "AdaptiveAvgPool2d-187            [-1, 640, 1, 1]               0\n",
      "          Conv2d-188             [-1, 40, 1, 1]          25,640\n",
      "            SiLU-189             [-1, 40, 1, 1]               0\n",
      "          Conv2d-190            [-1, 640, 1, 1]          26,240\n",
      "         Sigmoid-191            [-1, 640, 1, 1]               0\n",
      "          SEUnit-192          [-1, 640, 14, 14]               0\n",
      "          Conv2d-193          [-1, 160, 14, 14]         102,400\n",
      "     BatchNorm2d-194          [-1, 160, 14, 14]             320\n",
      "        Identity-195          [-1, 160, 14, 14]               0\n",
      " StochasticDepth-196          [-1, 160, 14, 14]               0\n",
      "          MBConv-197          [-1, 160, 14, 14]               0\n",
      "          Conv2d-198          [-1, 640, 14, 14]         102,400\n",
      "     BatchNorm2d-199          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-200          [-1, 640, 14, 14]               0\n",
      "          Conv2d-201          [-1, 640, 14, 14]           5,760\n",
      "     BatchNorm2d-202          [-1, 640, 14, 14]           1,280\n",
      "            SiLU-203          [-1, 640, 14, 14]               0\n",
      "AdaptiveAvgPool2d-204            [-1, 640, 1, 1]               0\n",
      "          Conv2d-205             [-1, 40, 1, 1]          25,640\n",
      "            SiLU-206             [-1, 40, 1, 1]               0\n",
      "          Conv2d-207            [-1, 640, 1, 1]          26,240\n",
      "         Sigmoid-208            [-1, 640, 1, 1]               0\n",
      "          SEUnit-209          [-1, 640, 14, 14]               0\n",
      "          Conv2d-210          [-1, 160, 14, 14]         102,400\n",
      "     BatchNorm2d-211          [-1, 160, 14, 14]             320\n",
      "        Identity-212          [-1, 160, 14, 14]               0\n",
      " StochasticDepth-213          [-1, 160, 14, 14]               0\n",
      "          MBConv-214          [-1, 160, 14, 14]               0\n",
      "          Conv2d-215          [-1, 960, 14, 14]         153,600\n",
      "     BatchNorm2d-216          [-1, 960, 14, 14]           1,920\n",
      "            SiLU-217          [-1, 960, 14, 14]               0\n",
      "          Conv2d-218          [-1, 960, 14, 14]           8,640\n",
      "     BatchNorm2d-219          [-1, 960, 14, 14]           1,920\n",
      "            SiLU-220          [-1, 960, 14, 14]               0\n",
      "AdaptiveAvgPool2d-221            [-1, 960, 1, 1]               0\n",
      "          Conv2d-222             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-223             [-1, 40, 1, 1]               0\n",
      "          Conv2d-224            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-225            [-1, 960, 1, 1]               0\n",
      "          SEUnit-226          [-1, 960, 14, 14]               0\n",
      "          Conv2d-227          [-1, 176, 14, 14]         168,960\n",
      "     BatchNorm2d-228          [-1, 176, 14, 14]             352\n",
      "        Identity-229          [-1, 176, 14, 14]               0\n",
      "          MBConv-230          [-1, 176, 14, 14]               0\n",
      "          Conv2d-231         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-232         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-233         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-234         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-235         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-236         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-237           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-238             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-239             [-1, 44, 1, 1]               0\n",
      "          Conv2d-240           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-241           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-242         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-243          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-244          [-1, 176, 14, 14]             352\n",
      "        Identity-245          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-246          [-1, 176, 14, 14]               0\n",
      "          MBConv-247          [-1, 176, 14, 14]               0\n",
      "          Conv2d-248         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-249         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-250         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-251         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-252         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-253         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-254           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-255             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-256             [-1, 44, 1, 1]               0\n",
      "          Conv2d-257           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-258           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-259         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-260          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-261          [-1, 176, 14, 14]             352\n",
      "        Identity-262          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-263          [-1, 176, 14, 14]               0\n",
      "          MBConv-264          [-1, 176, 14, 14]               0\n",
      "          Conv2d-265         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-266         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-267         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-268         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-269         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-270         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-271           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-272             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-273             [-1, 44, 1, 1]               0\n",
      "          Conv2d-274           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-275           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-276         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-277          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-278          [-1, 176, 14, 14]             352\n",
      "        Identity-279          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-280          [-1, 176, 14, 14]               0\n",
      "          MBConv-281          [-1, 176, 14, 14]               0\n",
      "          Conv2d-282         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-283         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-284         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-285         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-286         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-287         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-288           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-289             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-290             [-1, 44, 1, 1]               0\n",
      "          Conv2d-291           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-292           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-293         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-294          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-295          [-1, 176, 14, 14]             352\n",
      "        Identity-296          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-297          [-1, 176, 14, 14]               0\n",
      "          MBConv-298          [-1, 176, 14, 14]               0\n",
      "          Conv2d-299         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-300         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-301         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-302         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-303         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-304         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-305           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-306             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-307             [-1, 44, 1, 1]               0\n",
      "          Conv2d-308           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-309           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-310         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-311          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-312          [-1, 176, 14, 14]             352\n",
      "        Identity-313          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-314          [-1, 176, 14, 14]               0\n",
      "          MBConv-315          [-1, 176, 14, 14]               0\n",
      "          Conv2d-316         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-317         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-318         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-319         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-320         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-321         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-322           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-323             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-324             [-1, 44, 1, 1]               0\n",
      "          Conv2d-325           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-326           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-327         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-328          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-329          [-1, 176, 14, 14]             352\n",
      "        Identity-330          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-331          [-1, 176, 14, 14]               0\n",
      "          MBConv-332          [-1, 176, 14, 14]               0\n",
      "          Conv2d-333         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-334         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-335         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-336         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-337         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-338         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-339           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-340             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-341             [-1, 44, 1, 1]               0\n",
      "          Conv2d-342           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-343           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-344         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-345          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-346          [-1, 176, 14, 14]             352\n",
      "        Identity-347          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-348          [-1, 176, 14, 14]               0\n",
      "          MBConv-349          [-1, 176, 14, 14]               0\n",
      "          Conv2d-350         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-351         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-352         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-353         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-354         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-355         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-356           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-357             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-358             [-1, 44, 1, 1]               0\n",
      "          Conv2d-359           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-360           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-361         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-362          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-363          [-1, 176, 14, 14]             352\n",
      "        Identity-364          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-365          [-1, 176, 14, 14]               0\n",
      "          MBConv-366          [-1, 176, 14, 14]               0\n",
      "          Conv2d-367         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-368         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-369         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-370         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-371         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-372         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-373           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-374             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-375             [-1, 44, 1, 1]               0\n",
      "          Conv2d-376           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-377           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-378         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-379          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-380          [-1, 176, 14, 14]             352\n",
      "        Identity-381          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-382          [-1, 176, 14, 14]               0\n",
      "          MBConv-383          [-1, 176, 14, 14]               0\n",
      "          Conv2d-384         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-385         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-386         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-387         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-388         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-389         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-390           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-391             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-392             [-1, 44, 1, 1]               0\n",
      "          Conv2d-393           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-394           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-395         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-396          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-397          [-1, 176, 14, 14]             352\n",
      "        Identity-398          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-399          [-1, 176, 14, 14]               0\n",
      "          MBConv-400          [-1, 176, 14, 14]               0\n",
      "          Conv2d-401         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-402         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-403         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-404         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-405         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-406         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-407           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-408             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-409             [-1, 44, 1, 1]               0\n",
      "          Conv2d-410           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-411           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-412         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-413          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-414          [-1, 176, 14, 14]             352\n",
      "        Identity-415          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-416          [-1, 176, 14, 14]               0\n",
      "          MBConv-417          [-1, 176, 14, 14]               0\n",
      "          Conv2d-418         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-419         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-420         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-421         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-422         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-423         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-424           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-425             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-426             [-1, 44, 1, 1]               0\n",
      "          Conv2d-427           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-428           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-429         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-430          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-431          [-1, 176, 14, 14]             352\n",
      "        Identity-432          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-433          [-1, 176, 14, 14]               0\n",
      "          MBConv-434          [-1, 176, 14, 14]               0\n",
      "          Conv2d-435         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-436         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-437         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-438         [-1, 1056, 14, 14]           9,504\n",
      "     BatchNorm2d-439         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-440         [-1, 1056, 14, 14]               0\n",
      "AdaptiveAvgPool2d-441           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-442             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-443             [-1, 44, 1, 1]               0\n",
      "          Conv2d-444           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-445           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-446         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-447          [-1, 176, 14, 14]         185,856\n",
      "     BatchNorm2d-448          [-1, 176, 14, 14]             352\n",
      "        Identity-449          [-1, 176, 14, 14]               0\n",
      " StochasticDepth-450          [-1, 176, 14, 14]               0\n",
      "          MBConv-451          [-1, 176, 14, 14]               0\n",
      "          Conv2d-452         [-1, 1056, 14, 14]         185,856\n",
      "     BatchNorm2d-453         [-1, 1056, 14, 14]           2,112\n",
      "            SiLU-454         [-1, 1056, 14, 14]               0\n",
      "          Conv2d-455           [-1, 1056, 7, 7]           9,504\n",
      "     BatchNorm2d-456           [-1, 1056, 7, 7]           2,112\n",
      "            SiLU-457           [-1, 1056, 7, 7]               0\n",
      "AdaptiveAvgPool2d-458           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-459             [-1, 44, 1, 1]          46,508\n",
      "            SiLU-460             [-1, 44, 1, 1]               0\n",
      "          Conv2d-461           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-462           [-1, 1056, 1, 1]               0\n",
      "          SEUnit-463           [-1, 1056, 7, 7]               0\n",
      "          Conv2d-464            [-1, 304, 7, 7]         321,024\n",
      "     BatchNorm2d-465            [-1, 304, 7, 7]             608\n",
      "        Identity-466            [-1, 304, 7, 7]               0\n",
      "          MBConv-467            [-1, 304, 7, 7]               0\n",
      "          Conv2d-468           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-469           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-470           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-471           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-472           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-473           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-474           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-475             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-476             [-1, 76, 1, 1]               0\n",
      "          Conv2d-477           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-478           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-479           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-480            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-481            [-1, 304, 7, 7]             608\n",
      "        Identity-482            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-483            [-1, 304, 7, 7]               0\n",
      "          MBConv-484            [-1, 304, 7, 7]               0\n",
      "          Conv2d-485           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-486           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-487           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-488           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-489           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-490           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-491           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-492             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-493             [-1, 76, 1, 1]               0\n",
      "          Conv2d-494           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-495           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-496           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-497            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-498            [-1, 304, 7, 7]             608\n",
      "        Identity-499            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-500            [-1, 304, 7, 7]               0\n",
      "          MBConv-501            [-1, 304, 7, 7]               0\n",
      "          Conv2d-502           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-503           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-504           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-505           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-506           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-507           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-508           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-509             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-510             [-1, 76, 1, 1]               0\n",
      "          Conv2d-511           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-512           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-513           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-514            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-515            [-1, 304, 7, 7]             608\n",
      "        Identity-516            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-517            [-1, 304, 7, 7]               0\n",
      "          MBConv-518            [-1, 304, 7, 7]               0\n",
      "          Conv2d-519           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-520           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-521           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-522           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-523           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-524           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-525           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-526             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-527             [-1, 76, 1, 1]               0\n",
      "          Conv2d-528           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-529           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-530           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-531            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-532            [-1, 304, 7, 7]             608\n",
      "        Identity-533            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-534            [-1, 304, 7, 7]               0\n",
      "          MBConv-535            [-1, 304, 7, 7]               0\n",
      "          Conv2d-536           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-537           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-538           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-539           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-540           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-541           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-542           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-543             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-544             [-1, 76, 1, 1]               0\n",
      "          Conv2d-545           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-546           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-547           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-548            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-549            [-1, 304, 7, 7]             608\n",
      "        Identity-550            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-551            [-1, 304, 7, 7]               0\n",
      "          MBConv-552            [-1, 304, 7, 7]               0\n",
      "          Conv2d-553           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-554           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-555           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-556           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-557           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-558           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-559           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-560             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-561             [-1, 76, 1, 1]               0\n",
      "          Conv2d-562           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-563           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-564           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-565            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-566            [-1, 304, 7, 7]             608\n",
      "        Identity-567            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-568            [-1, 304, 7, 7]               0\n",
      "          MBConv-569            [-1, 304, 7, 7]               0\n",
      "          Conv2d-570           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-571           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-572           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-573           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-574           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-575           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-576           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-577             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-578             [-1, 76, 1, 1]               0\n",
      "          Conv2d-579           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-580           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-581           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-582            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-583            [-1, 304, 7, 7]             608\n",
      "        Identity-584            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-585            [-1, 304, 7, 7]               0\n",
      "          MBConv-586            [-1, 304, 7, 7]               0\n",
      "          Conv2d-587           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-588           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-589           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-590           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-591           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-592           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-593           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-594             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-595             [-1, 76, 1, 1]               0\n",
      "          Conv2d-596           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-597           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-598           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-599            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-600            [-1, 304, 7, 7]             608\n",
      "        Identity-601            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-602            [-1, 304, 7, 7]               0\n",
      "          MBConv-603            [-1, 304, 7, 7]               0\n",
      "          Conv2d-604           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-605           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-606           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-607           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-608           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-609           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-610           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-611             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-612             [-1, 76, 1, 1]               0\n",
      "          Conv2d-613           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-614           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-615           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-616            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-617            [-1, 304, 7, 7]             608\n",
      "        Identity-618            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-619            [-1, 304, 7, 7]               0\n",
      "          MBConv-620            [-1, 304, 7, 7]               0\n",
      "          Conv2d-621           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-622           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-623           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-624           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-625           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-626           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-627           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-628             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-629             [-1, 76, 1, 1]               0\n",
      "          Conv2d-630           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-631           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-632           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-633            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-634            [-1, 304, 7, 7]             608\n",
      "        Identity-635            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-636            [-1, 304, 7, 7]               0\n",
      "          MBConv-637            [-1, 304, 7, 7]               0\n",
      "          Conv2d-638           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-639           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-640           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-641           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-642           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-643           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-644           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-645             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-646             [-1, 76, 1, 1]               0\n",
      "          Conv2d-647           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-648           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-649           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-650            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-651            [-1, 304, 7, 7]             608\n",
      "        Identity-652            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-653            [-1, 304, 7, 7]               0\n",
      "          MBConv-654            [-1, 304, 7, 7]               0\n",
      "          Conv2d-655           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-656           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-657           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-658           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-659           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-660           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-661           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-662             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-663             [-1, 76, 1, 1]               0\n",
      "          Conv2d-664           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-665           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-666           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-667            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-668            [-1, 304, 7, 7]             608\n",
      "        Identity-669            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-670            [-1, 304, 7, 7]               0\n",
      "          MBConv-671            [-1, 304, 7, 7]               0\n",
      "          Conv2d-672           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-673           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-674           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-675           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-676           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-677           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-678           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-679             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-680             [-1, 76, 1, 1]               0\n",
      "          Conv2d-681           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-682           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-683           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-684            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-685            [-1, 304, 7, 7]             608\n",
      "        Identity-686            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-687            [-1, 304, 7, 7]               0\n",
      "          MBConv-688            [-1, 304, 7, 7]               0\n",
      "          Conv2d-689           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-690           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-691           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-692           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-693           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-694           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-695           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-696             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-697             [-1, 76, 1, 1]               0\n",
      "          Conv2d-698           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-699           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-700           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-701            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-702            [-1, 304, 7, 7]             608\n",
      "        Identity-703            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-704            [-1, 304, 7, 7]               0\n",
      "          MBConv-705            [-1, 304, 7, 7]               0\n",
      "          Conv2d-706           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-707           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-708           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-709           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-710           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-711           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-712           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-713             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-714             [-1, 76, 1, 1]               0\n",
      "          Conv2d-715           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-716           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-717           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-718            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-719            [-1, 304, 7, 7]             608\n",
      "        Identity-720            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-721            [-1, 304, 7, 7]               0\n",
      "          MBConv-722            [-1, 304, 7, 7]               0\n",
      "          Conv2d-723           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-724           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-725           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-726           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-727           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-728           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-729           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-730             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-731             [-1, 76, 1, 1]               0\n",
      "          Conv2d-732           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-733           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-734           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-735            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-736            [-1, 304, 7, 7]             608\n",
      "        Identity-737            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-738            [-1, 304, 7, 7]               0\n",
      "          MBConv-739            [-1, 304, 7, 7]               0\n",
      "          Conv2d-740           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-741           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-742           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-743           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-744           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-745           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-746           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-747             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-748             [-1, 76, 1, 1]               0\n",
      "          Conv2d-749           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-750           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-751           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-752            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-753            [-1, 304, 7, 7]             608\n",
      "        Identity-754            [-1, 304, 7, 7]               0\n",
      " StochasticDepth-755            [-1, 304, 7, 7]               0\n",
      "          MBConv-756            [-1, 304, 7, 7]               0\n",
      "          Conv2d-757           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-758           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-759           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-760           [-1, 1824, 7, 7]          16,416\n",
      "     BatchNorm2d-761           [-1, 1824, 7, 7]           3,648\n",
      "            SiLU-762           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-763           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-764             [-1, 76, 1, 1]         138,700\n",
      "            SiLU-765             [-1, 76, 1, 1]               0\n",
      "          Conv2d-766           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-767           [-1, 1824, 1, 1]               0\n",
      "          SEUnit-768           [-1, 1824, 7, 7]               0\n",
      "          Conv2d-769            [-1, 512, 7, 7]         933,888\n",
      "     BatchNorm2d-770            [-1, 512, 7, 7]           1,024\n",
      "        Identity-771            [-1, 512, 7, 7]               0\n",
      "          MBConv-772            [-1, 512, 7, 7]               0\n",
      "          Conv2d-773           [-1, 3072, 7, 7]       1,572,864\n",
      "     BatchNorm2d-774           [-1, 3072, 7, 7]           6,144\n",
      "            SiLU-775           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-776           [-1, 3072, 7, 7]          27,648\n",
      "     BatchNorm2d-777           [-1, 3072, 7, 7]           6,144\n",
      "            SiLU-778           [-1, 3072, 7, 7]               0\n",
      "AdaptiveAvgPool2d-779           [-1, 3072, 1, 1]               0\n",
      "          Conv2d-780            [-1, 128, 1, 1]         393,344\n",
      "            SiLU-781            [-1, 128, 1, 1]               0\n",
      "          Conv2d-782           [-1, 3072, 1, 1]         396,288\n",
      "         Sigmoid-783           [-1, 3072, 1, 1]               0\n",
      "          SEUnit-784           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-785            [-1, 512, 7, 7]       1,572,864\n",
      "     BatchNorm2d-786            [-1, 512, 7, 7]           1,024\n",
      "        Identity-787            [-1, 512, 7, 7]               0\n",
      " StochasticDepth-788            [-1, 512, 7, 7]               0\n",
      "          MBConv-789            [-1, 512, 7, 7]               0\n",
      "          Conv2d-790           [-1, 3072, 7, 7]       1,572,864\n",
      "     BatchNorm2d-791           [-1, 3072, 7, 7]           6,144\n",
      "            SiLU-792           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-793           [-1, 3072, 7, 7]          27,648\n",
      "     BatchNorm2d-794           [-1, 3072, 7, 7]           6,144\n",
      "            SiLU-795           [-1, 3072, 7, 7]               0\n",
      "AdaptiveAvgPool2d-796           [-1, 3072, 1, 1]               0\n",
      "          Conv2d-797            [-1, 128, 1, 1]         393,344\n",
      "            SiLU-798            [-1, 128, 1, 1]               0\n",
      "          Conv2d-799           [-1, 3072, 1, 1]         396,288\n",
      "         Sigmoid-800           [-1, 3072, 1, 1]               0\n",
      "          SEUnit-801           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-802            [-1, 512, 7, 7]       1,572,864\n",
      "     BatchNorm2d-803            [-1, 512, 7, 7]           1,024\n",
      "        Identity-804            [-1, 512, 7, 7]               0\n",
      " StochasticDepth-805            [-1, 512, 7, 7]               0\n",
      "          MBConv-806            [-1, 512, 7, 7]               0\n",
      "          Conv2d-807           [-1, 3072, 7, 7]       1,572,864\n",
      "     BatchNorm2d-808           [-1, 3072, 7, 7]           6,144\n",
      "            SiLU-809           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-810           [-1, 3072, 7, 7]          27,648\n",
      "     BatchNorm2d-811           [-1, 3072, 7, 7]           6,144\n",
      "            SiLU-812           [-1, 3072, 7, 7]               0\n",
      "AdaptiveAvgPool2d-813           [-1, 3072, 1, 1]               0\n",
      "          Conv2d-814            [-1, 128, 1, 1]         393,344\n",
      "            SiLU-815            [-1, 128, 1, 1]               0\n",
      "          Conv2d-816           [-1, 3072, 1, 1]         396,288\n",
      "         Sigmoid-817           [-1, 3072, 1, 1]               0\n",
      "          SEUnit-818           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-819            [-1, 512, 7, 7]       1,572,864\n",
      "     BatchNorm2d-820            [-1, 512, 7, 7]           1,024\n",
      "        Identity-821            [-1, 512, 7, 7]               0\n",
      " StochasticDepth-822            [-1, 512, 7, 7]               0\n",
      "          MBConv-823            [-1, 512, 7, 7]               0\n",
      "          Conv2d-824           [-1, 3072, 7, 7]       1,572,864\n",
      "     BatchNorm2d-825           [-1, 3072, 7, 7]           6,144\n",
      "            SiLU-826           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-827           [-1, 3072, 7, 7]          27,648\n",
      "     BatchNorm2d-828           [-1, 3072, 7, 7]           6,144\n",
      "            SiLU-829           [-1, 3072, 7, 7]               0\n",
      "AdaptiveAvgPool2d-830           [-1, 3072, 1, 1]               0\n",
      "          Conv2d-831            [-1, 128, 1, 1]         393,344\n",
      "            SiLU-832            [-1, 128, 1, 1]               0\n",
      "          Conv2d-833           [-1, 3072, 1, 1]         396,288\n",
      "         Sigmoid-834           [-1, 3072, 1, 1]               0\n",
      "          SEUnit-835           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-836            [-1, 512, 7, 7]       1,572,864\n",
      "     BatchNorm2d-837            [-1, 512, 7, 7]           1,024\n",
      "        Identity-838            [-1, 512, 7, 7]               0\n",
      " StochasticDepth-839            [-1, 512, 7, 7]               0\n",
      "          MBConv-840            [-1, 512, 7, 7]               0\n",
      "          Conv2d-841           [-1, 1280, 7, 7]         655,360\n",
      "     BatchNorm2d-842           [-1, 1280, 7, 7]           2,560\n",
      "            SiLU-843           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-844           [-1, 1280, 1, 1]               0\n",
      "         Flatten-845                 [-1, 1280]               0\n",
      "         Dropout-846                 [-1, 1280]               0\n",
      "          Linear-847                 [-1, 7000]       8,967,000\n",
      "================================================================\n",
      "Total params: 61,825,356\n",
      "Trainable params: 61,825,356\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 538.86\n",
      "Params size (MB): 235.85\n",
      "Estimated Total Size (MB): 775.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 7000])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    images = images.to(device)\n",
    "    print(model(images).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1280])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    images = images.to(device)\n",
    "    print(model(images, return_feats=True).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from resnet50 import Bottleneck, Block, ResNet\n",
    "\n",
    "\n",
    "# def ResNet50():\n",
    "#     return ResNet(Bottleneck, [3,4,6,3], num_classes=7000, num_channels=3)\n",
    "    \n",
    "# def ResNet101():\n",
    "#     return ResNet(Bottleneck, [3,4,23,3], num_classes=7000, num_channels=3)\n",
    "\n",
    "# def ResNet152():\n",
    "#     return ResNet(Bottleneck, [3,8,36,3], num_classes=7000, num_channels=3)\n",
    "\n",
    "# model = ResNet50().to(device)\n",
    "# summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZCn0qHuZRKj"
   },
   "source": [
    "# Setup everything for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'lr': 0.2,\n",
       " 'epochs': 100,\n",
       " 'optimizer': 'SGD',\n",
       " 'weight_decay': 1e-05,\n",
       " 'scheduler': 'CosineLR',\n",
       " 'LR_stepsize': 'batch*epochs',\n",
       " 'smoothing': 0.1,\n",
       " 'dropout': 0.15}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UowI9OcUYPjP"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=config['smoothing'])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "# TODO: Implement a scheduler (Optional but Highly Recommended)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs']*len(train_loader), eta_min=1e-09)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.00001, last_epoch=-1)\n",
    "# You can try ReduceLRonPlateau, StepLR, MultistepLR, CosineAnnealing, etc.\n",
    "scaler = torch.cuda.amp.GradScaler() # Good news. We have FP16 (Mixed precision training) implemented for you\n",
    "# It is useful only in the case of compatible GPUs such as T4/V100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzM11HtcboYv",
    "tags": []
   },
   "source": [
    "# Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bgSw6iJJavBZ"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    # Progress Bar \n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5) \n",
    "    \n",
    "    num_correct = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        \n",
    "        optimizer.zero_grad() # Zero gradients\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast(): # This implements mixed precision. Thats it! \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Update no. of correct predictions & loss as we iterate\n",
    "        num_correct += int((torch.argmax(outputs, axis=1) == labels).sum())\n",
    "        total_loss += float(loss.item())\n",
    "\n",
    "        # tqdm lets you add some details so you can monitor training as you train.\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            num_correct=num_correct,\n",
    "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        \n",
    "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
    "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
    "        scaler.update() \n",
    "\n",
    "        # TODO? Depending on your choice of scheduler,\n",
    "        # You may want to call some schdulers inside the train function. What are these?\n",
    "        \n",
    "      \n",
    "        batch_bar.update() # Update tqdm bar\n",
    "    \n",
    "        scheduler.step()\n",
    "\n",
    "    batch_bar.close() # You need this to close the tqdm bar\n",
    "\n",
    "    acc = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
    "    total_loss = float(total_loss / len(dataloader))\n",
    "\n",
    "    return acc, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "m5V2UdnpdEoK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion):\n",
    "  \n",
    "    model.eval()\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
    "\n",
    "    num_correct = 0.0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        \n",
    "        # Move images to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Get model outputs\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        num_correct += int((torch.argmax(outputs, axis=1) == labels).sum())\n",
    "        total_loss += float(loss.item())\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            num_correct=num_correct)\n",
    "\n",
    "        batch_bar.update()\n",
    "        \n",
    "    batch_bar.close()\n",
    "    acc = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
    "    total_loss = float(total_loss / len(dataloader))\n",
    "    return acc, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cmotca6pcLLY"
   },
   "outputs": [],
   "source": [
    "gc.collect() # These commands help you when you face CUDA OOM error\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mBgKGkXLrdJ"
   },
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Ix62_BkaLr_D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jiin/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"db668044fcf11bc7352d5c79ac0deb75ac86a16b\") #API Key is in your wandb account, under settings (wandb.ai/settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "VG0vmsmbRYEi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/usr/SSD/jiin/CMU/IDL/HW2P2/wandb/run-20221028_011918-2ku0unpx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jiin/hw2p2-recognition/runs/2ku0unpx\" target=\"_blank\">effinet</a></strong> to <a href=\"https://wandb.ai/jiin/hw2p2-recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create your wandb run\n",
    "run = wandb.init(\n",
    "    name = \"effinet\", ## Wandb creates random run names if you skip this field\n",
    "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"hw2p2-recognition\", ### Project should be created in your wandb account \n",
    "    config = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQkRw1FvLqYe"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './cls_result'\n",
    "model_directory = 'effinet'\n",
    "exp_name = '1_original.pth'\n",
    "if not os.path.exists(root + '/' + model_directory):\n",
    "    os.mkdir(root + '/' + model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqWO8Edb0BK2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                                                                               | 1/2188 [00:00<29:55,  1.22it/s, acc=0.0000%, loss=8.8354, lr=0.2000, num_correct=0]/home/jiin/anaconda3/envs/torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100: \n",
      "Train Acc 0.0129%\t Train Loss 8.8545\t Learning Rate 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 0.0428%\t Val Loss 8.8168\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/100: \n",
      "Train Acc 0.0514%\t Train Loss 8.6561\t Learning Rate 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 0.1400%\t Val Loss 8.5352\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/100: \n",
      "Train Acc 0.2192%\t Train Loss 8.1042\t Learning Rate 0.1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 0.5770%\t Val Loss 7.8629\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/100: \n",
      "Train Acc 0.9769%\t Train Loss 7.4341\t Learning Rate 0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 1.9481%\t Val Loss 7.1345\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/100: \n",
      "Train Acc 3.1907%\t Train Loss 6.7705\t Learning Rate 0.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 4.8875%\t Val Loss 6.5606\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/100: \n",
      "Train Acc 7.7118%\t Train Loss 6.1485\t Learning Rate 0.1988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 9.7492%\t Val Loss 6.2729\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/100: \n",
      "Train Acc 14.0104%\t Train Loss 5.5871\t Learning Rate 0.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 14.5195%\t Val Loss 5.6478\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/100: \n",
      "Train Acc 21.7750%\t Train Loss 5.0704\t Learning Rate 0.1976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 20.3468%\t Val Loss 5.2949\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/100: \n",
      "Train Acc 29.6525%\t Train Loss 4.6187\t Learning Rate 0.1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 29.4333%\t Val Loss 4.7738\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100: \n",
      "Train Acc 37.3707%\t Train Loss 4.2228\t Learning Rate 0.1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 33.4695%\t Val Loss 4.6131\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/100: \n",
      "Train Acc 44.9554%\t Train Loss 3.8723\t Learning Rate 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 40.2108%\t Val Loss 4.2738\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/100: \n",
      "Train Acc 51.6496%\t Train Loss 3.5616\t Learning Rate 0.1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 43.3987%\t Val Loss 4.1116\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/100: \n",
      "Train Acc 57.9168%\t Train Loss 3.2936\t Learning Rate 0.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 48.2918%\t Val Loss 3.9064\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/100: \n",
      "Train Acc 63.4176%\t Train Loss 3.0567\t Learning Rate 0.1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 51.2197%\t Val Loss 3.7888\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/100: \n",
      "Train Acc 68.3522%\t Train Loss 2.8456\t Learning Rate 0.1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 51.9396%\t Val Loss 3.7422\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/100: \n",
      "Train Acc 72.7605%\t Train Loss 2.6596\t Learning Rate 0.1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 56.2871%\t Val Loss 3.5625\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/100: \n",
      "Train Acc 77.0595%\t Train Loss 2.4927\t Learning Rate 0.1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 59.9863%\t Val Loss 3.4255\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/100: \n",
      "Train Acc 80.5480%\t Train Loss 2.3451\t Learning Rate 0.1861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 61.4602%\t Val Loss 3.3859\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/100: \n",
      "Train Acc 83.9301%\t Train Loss 2.2123\t Learning Rate 0.1844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 62.3429%\t Val Loss 3.3490\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   5%|                                                                     | 115/2188 [00:34<10:21,  3.34it/s, acc=89.2663%, loss=2.0180, lr=0.1826, num_correct=6570]"
     ]
    }
   ],
   "source": [
    "best_valacc = 0.0\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "\n",
    "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    train_acc, train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    \n",
    "    print(\"\\nEpoch {}/{}: \\nTrain Acc {:.04f}%\\t Train Loss {:.04f}\\t Learning Rate {:.04f}\".format(\n",
    "        epoch + 1,\n",
    "        config['epochs'],\n",
    "        train_acc,\n",
    "        train_loss,\n",
    "        curr_lr))\n",
    "    \n",
    "    val_acc, val_loss = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(val_acc, val_loss))\n",
    "\n",
    "    wandb.log({\"train_loss\":train_loss, 'train_Acc': train_acc, 'validation_Acc':val_acc, \n",
    "               'validation_loss': val_loss, \"learning_Rate\": curr_lr})\n",
    "    \n",
    "    # If you are using a scheduler in your train function within your iteration loop, you may want to log\n",
    "    # your learning rate differently \n",
    "    \n",
    "\n",
    "    # #Save model in drive location if val_acc is better than best recorded val_acc\n",
    "    if val_acc >= best_valacc:\n",
    "#         path = os.path.join(root, model_directory, 'checkpoint' + '.pth')\n",
    "        path = os.path.join(root, model_directory, exp_name)\n",
    "        print(\"Saving model\")\n",
    "        torch.save({'model_state_dict':model.state_dict(),\n",
    "              'optimizer_state_dict':optimizer.state_dict(),\n",
    "              'scheduler_state_dict':scheduler.state_dict(),\n",
    "              'val_acc': val_acc, \n",
    "              'epoch': epoch}, path)\n",
    "        best_valacc = val_acc\n",
    "        \n",
    "        wandb.save('checkpoint.pth')\n",
    "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpgCHImRkYQW"
   },
   "source": [
    "# Classification Task: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(root, model_directory, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root, model_directory, exp_name))['model_state_dict'])\n",
    "print(torch.load(os.path.join(root, model_directory, exp_name))['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2WQEUjXkWvo"
   },
   "outputs": [],
   "source": [
    "def test(model,dataloader):\n",
    "\n",
    "  model.eval()\n",
    "  batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Test')\n",
    "  test_results = []\n",
    "  \n",
    "  for i, (images) in enumerate(dataloader):\n",
    "      # TODO: Finish predicting on the test set.\n",
    "      images = images.to(device)\n",
    "\n",
    "      with torch.inference_mode():\n",
    "        outputs = model(images)\n",
    "\n",
    "      outputs = torch.argmax(outputs, axis=1).detach().cpu().numpy().tolist()\n",
    "      test_results.extend(outputs)\n",
    "      \n",
    "      batch_bar.update()\n",
    "      \n",
    "  batch_bar.close()\n",
    "  return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7R1lcCAzULc",
    "outputId": "ed1d1147-46d3-4a6c-832f-6dbb2b0bde8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_results = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqfUzwS2L1gx"
   },
   "source": [
    "## Generate csv to submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vob9a2-HkW_V"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(root, model_directory, \"effinet_{}.csv\".format(exp_name[:-4])), \"w+\") as f:\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i in range(len(test_dataset)):\n",
    "        f.write(\"{},{}\\n\".format(str(i).zfill(6) + \".jpg\", test_results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c 11-785-f22-hw2p2-classification -f cls_result/ResNet50/resnet50_1_normalize.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsJx1l1T4twC"
   },
   "source": [
    "# Verification Task: Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoBFFF8-Lpvj"
   },
   "source": [
    "The verification task consists of the following generalized scenario:\n",
    "- You are given X unknown identitites \n",
    "- You are given Y known identitites\n",
    "- Your goal is to match X unknown identities to Y known identities.\n",
    "\n",
    "We have given you a verification dataset, that consists of 1000 known identities, and 1000 unknown identities. The 1000 unknown identities are split into dev (200) and test (800). Your goal is to compare the unknown identities to the 1000 known identities and assign an identity to each image from the set of unknown identities. \n",
    "\n",
    "Your will use/finetune your model trained for classification to compare images between known and unknown identities using a similarity metric and assign labels to the unknown identities. \n",
    "\n",
    "This will judge your model's performance in terms of the quality of embeddings/features it generates on images/faces it has never seen during training for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9aY5o-suWdn",
    "outputId": "e641fa12-af84-411f-c21c-a70947518d4c"
   },
   "outputs": [],
   "source": [
    "known_regex = \"data/verification/known/*/*\"\n",
    "known_paths = [i.split('/')[-2] for i in sorted(glob.glob(known_regex))] \n",
    "# This obtains the list of known identities from the known folder\n",
    "\n",
    "unknown_regex = \"data/verification/unknown_dev/*\" #Change the directory accordingly for the test set\n",
    "\n",
    "# We load the images from known and unknown folders\n",
    "unknown_images = [Image.open(p) for p in tqdm(sorted(glob.glob(unknown_regex)))]\n",
    "known_images = [Image.open(p) for p in tqdm(sorted(glob.glob(known_regex)))]\n",
    "\n",
    "# Why do you need only ToTensor() here?\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean, std)])\n",
    "\n",
    "unknown_images = torch.stack([transforms(x) for x in unknown_images])\n",
    "known_images  = torch.stack([transforms(y) for y in known_images ])\n",
    "#Print your shapes here to understand what we have done\n",
    "\n",
    "# You can use other similarity metrics like Euclidean Distance if you wish\n",
    "similarity_metric = torch.nn.CosineSimilarity(dim= 1, eps= 1e-6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rk1LS0BRxFHM",
    "outputId": "ad9694ee-1075-4709-b50d-1ce6a049dc14"
   },
   "outputs": [],
   "source": [
    "def eval_verification(unknown_images, known_images, model, similarity, batch_size= config['batch_size'], mode='val'): \n",
    "\n",
    "    unknown_feats, known_feats = [], []\n",
    "\n",
    "    batch_bar = tqdm(total=len(unknown_images)//batch_size, dynamic_ncols=True, position=0, leave=False, desc=mode)\n",
    "    model.eval()\n",
    "\n",
    "    # We load the images as batches for memory optimization and avoiding CUDA OOM errors\n",
    "    for i in range(0, unknown_images.shape[0], batch_size):\n",
    "        unknown_batch = unknown_images[i:i+batch_size] # Slice a given portion upto batch_size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            unknown_feat = model(unknown_batch.float().to(device), return_feats=True) #Get features from model         \n",
    "        unknown_feats.append(unknown_feat)\n",
    "        batch_bar.update()\n",
    "    \n",
    "    batch_bar.close()\n",
    "    \n",
    "    batch_bar = tqdm(total=len(known_images)//batch_size, dynamic_ncols=True, position=0, leave=False, desc=mode)\n",
    "    \n",
    "    for i in range(0, known_images.shape[0], batch_size):\n",
    "        known_batch = known_images[i:i+batch_size] \n",
    "        with torch.no_grad():\n",
    "              known_feat = model(known_batch.float().to(device), return_feats=True)\n",
    "          \n",
    "        known_feats.append(known_feat)\n",
    "        batch_bar.update()\n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    # Concatenate all the batches\n",
    "    unknown_feats = torch.cat(unknown_feats, dim=0)\n",
    "    known_feats = torch.cat(known_feats, dim=0)\n",
    "\n",
    "    similarity_values = torch.stack([similarity(unknown_feats, known_feature) for known_feature in known_feats])\n",
    "    # Print the inner list comprehension in a separate cell - what is really happening?\n",
    "\n",
    "    predictions = similarity_values.argmax(0).cpu().numpy() #Why are we doing an argmax here?\n",
    "\n",
    "    # Map argmax indices to identity strings\n",
    "    pred_id_strings = [known_paths[i] for i in predictions]\n",
    "    \n",
    "    if mode == 'val':\n",
    "      true_ids = pd.read_csv('data/verification/dev_identities.csv')['label'].tolist()\n",
    "      accuracy = accuracy_score(pred_id_strings, true_ids)\n",
    "      print(\"Verification Accuracy = {}\".format(accuracy))\n",
    "    \n",
    "    return pred_id_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMC7FacaUnJ7"
   },
   "outputs": [],
   "source": [
    "pred_id_strings = eval_verification(unknown_images, known_images, model, similarity_metric, config['batch_size'], mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_regex = \"data/verification/unknown_test/*\" #Change the directory accordingly for the test set\n",
    "\n",
    "# We load the images from known and unknown folders\n",
    "unknown_images = [Image.open(p) for p in tqdm(sorted(glob.glob(unknown_regex)))]\n",
    "\n",
    "# Why do you need only ToTensor() here?\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()])\n",
    "\n",
    "unknown_images = torch.stack([transforms(x) for x in unknown_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_id_strings = eval_verification(unknown_images, known_images, model, similarity_metric, config['batch_size'], mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_id_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './vrf_result'\n",
    "model_directory = 'effinet'\n",
    "# exp_name = '0_original.pth'\n",
    "if not os.path.exists(root + '/' + model_directory):\n",
    "    os.mkdir(root + '/' + model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fD-r-HmsAeWV"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(root, model_directory, \"effinet_{}.csv\".format(exp_name[:-4])), \"w+\") as f:\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i in range(len(pred_id_strings)):\n",
    "        f.write(\"{},{}\\n\".format(i, pred_id_strings[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c 11-785-f22-hw2p2-verification -f vrf_result/ResNet50/resnet50_1_normalize.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
